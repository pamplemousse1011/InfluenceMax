{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c38c8-33e5-43a0-92a4-f786f0b26567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import blackhc.laaos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the current file's directory\n",
    "current_working_directory = Path.cwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_path = current_working_directory.parent\n",
    "\n",
    "# Get the data-out directory\n",
    "data_out_path = parent_path.joinpath('data-out', 'CIFAR10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b3f73",
   "metadata": {},
   "source": [
    "## Retrieve the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a86b83",
   "metadata": {},
   "source": [
    "### CIFAR10 (Preactivation-Resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800bbe6",
   "metadata": {},
   "source": [
    "At each acquisition, we acquire a new set of hyperparameters $\\xi_t$, with which we train a model $f_{\\hat{\\theta}_t}$ with parameters $\\hat{\\theta}_t:=\\hat{\\theta}_t(\\xi_t)$ on the training data $\\mathcal{D}_{\\mathrm{train}}$. We then evaluate its performance on the training data, the mean negative log likelihood loss $L_t\\big(\\hat{\\theta}_{t};\\,\\mathcal{D}_{\\mathrm{train}}\\big)$. \n",
    "\n",
    "Given all $t$ models, we can get the model with best training performance: \n",
    "$$i_t^\\ast = \\arg\\min_{1\\le i\\le t} L_i\\big(\\hat{\\theta}_{i};\\,\\mathcal{D}_{\\mathrm{train}}\\big)$$ \n",
    "We then use the corresponding trained model $f_{\\hat{\\theta}_{i^\\ast}}$ with $\\hat{\\theta}_{i^\\ast}:=\\hat{\\theta}_{i^\\ast}(\\xi_{i^\\ast})$ to predict on the target data $\\mathcal{D}_{\\mathrm{targt}}$ and obtain the target prediction loss \n",
    "$$u_t=L_{i^\\ast}\\big(\\hat{\\theta}_{i^\\ast};\\,\\mathcal{D}_{\\mathrm{targt}}\\big).$$ \n",
    "\n",
    "Plot $u_t$ as a function of $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93975fc-5111-4947-88ef-c630d5372322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "\n",
    "output_files = [] \n",
    "\n",
    " \n",
    "pattern = str(data_out_path.joinpath(data_out_path, '*.py'))  \n",
    "for filename in glob.glob(pattern):\n",
    "    output_files.append(filename)\n",
    "\n",
    "len(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d83925-0eb6-40bf-8ee3-6d63f6173764",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"dataset\", \"var\", \"acquisition_method\", \"trial\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for filename in output_files:\n",
    "    file_split = filename.split('/')[-1].split('_')\n",
    "    dataset = file_split[0]\n",
    "    acquisition_method = file_split[-1].split('.')[0]\n",
    "    trial = int(file_split[-2][5:])\n",
    "    var = float(file_split[2][3:])\n",
    "    file_saved = blackhc.laaos.safe_load(filename) \n",
    "    single_output=[]\n",
    "    if 'iterations' in file_saved:\n",
    "        for item in file_saved['iterations']:\n",
    "            single_output.append([item['tol']])\n",
    "        tol_dct = dict(zip(iter(range(0,len(single_output))), single_output))\n",
    "        single_df = pd.DataFrame({'dataset': dataset, 'var': var, \n",
    "                                  'acquisition_method': acquisition_method, \n",
    "                                  'trial':trial,  **tol_dct})\n",
    "        df = pd.concat([df, single_df], ignore_index = True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96455e06-6c4a-4d02-8351-8dc61248bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "othermethods =['gp+ei', 'gp+kg', 'gp+mes', 'gp+ucb']  \n",
    "\n",
    "color_pool = ['C'+str(i) for i in range(2+len(othermethods))]\n",
    "\n",
    "dataset ='CIFAR10-preactrn'  \n",
    "var = 0\n",
    " \n",
    "for j, method in enumerate(othermethods):\n",
    "     \n",
    "    df_inv = df.loc[(df['dataset'] == dataset) & (df['acquisition_method'] == method) & (df['var']==var) ]\n",
    "    out_inv = df_inv.dropna(axis=1).drop(columns=['dataset','acquisition_method','trial','var']).to_numpy()\n",
    "    x = np.arange(0,out_inv.shape[-1])\n",
    "    out_inv = np.abs(out_inv) \n",
    "    y = out_inv.mean(0)\n",
    "    e = out_inv.std(0) # 2*sigma ~ 95% confidence region\n",
    "    plt.plot(x, y, '--', color=color_pool[2+j], label=method) \n",
    "    plt.errorbar(x, y, yerr=[e, e], fmt='o', color=color_pool[2+j], ecolor=color_pool[2+j], capsize=3, # capthick=0.2, \n",
    "             alpha=0.4)\n",
    "    plt.scatter(x, y, color=color_pool[2+j], edgecolor='w', zorder=5) # alpha=0.5\n",
    "   \n",
    "\n",
    "\n",
    "df_inv = df.loc[(df['dataset'] == dataset) & (df['acquisition_method'] == 'infmax') & (df['var']==var)]\n",
    "out_inv = df_inv.dropna(axis=1).drop(columns=['dataset','acquisition_method','trial','var']).to_numpy()\n",
    "out_inv = np.abs(out_inv)\n",
    "x = np.arange(0,out_inv.shape[-1])\n",
    "y = out_inv.mean(0)\n",
    "e = out_inv.std(0) # 2*sigma ~ 95% confidence region\n",
    "plt.plot(x, y, '--',  color=color_pool[0], label='infmax')\n",
    "plt.scatter(x, y, color=color_pool[0], edgecolor='w', zorder=5) # edgecolor='w',alpha=0.5\n",
    "\n",
    "plt.errorbar(x, y, yerr=[e, e], \n",
    "             fmt='o', \n",
    "             color=color_pool[0], \n",
    "             ecolor=color_pool[0], \n",
    "             capsize=3,\n",
    "             # capthick=0.2, \n",
    "             alpha=0.4)\n",
    "    \n",
    "\n",
    "xlim_upper = 12\n",
    "xlim_lower = 0   \n",
    "plt.xlabel('Acquisition step')\n",
    "plt.ylabel('Test Regret')\n",
    "plt.xlim([xlim_lower, xlim_upper]) \n",
    "plt.title(f\"Hyperparameter Optimization\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join('/Users/weichiyao/Desktop/',  f\"HPO_{dataset}.pdf\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7612b340",
   "metadata": {},
   "source": [
    "#### ORACLE \n",
    "This gives the results if we know the oracle, i.e., at each acquisition (we have a new model trained with this set of new hyperparameters), we evaluate the target loss and note down the lowest target loss among all acquisitions \n",
    "$$v_t = \\arg\\min_{1\\le i\\le t} L_i(\\hat{\\theta}_i; \\,\\mathcal{D}_{\\mathrm{targt}}),\\quad\\hat{\\theta}_i:=\\hat{\\theta}_i(\\xi_i).$$\n",
    "\n",
    "Plot $v_t$ as a function of $t$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab07aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle=True\n",
    "if Oracle:\n",
    "    column_names = [\"dataset\", \"var\", \"acquisition_method\", \"trial\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for filename in output_files:\n",
    "        file_split = filename.split('/')[-1].split('_')\n",
    "        dataset = file_split[0]\n",
    "        acquisition_method = file_split[-1].split('.')[0]\n",
    "        trial = int(file_split[-2][5:])\n",
    "        var = float(file_split[2][3:])\n",
    "        file_saved = blackhc.laaos.safe_load(filename) \n",
    "        single_output=[[min(file_saved['initial_samples']['init_y_targt'])]]\n",
    "        \n",
    "        if 'iterations' in file_saved:\n",
    "            for item in file_saved['iterations']:\n",
    "                curr_min = min(single_output)[0]\n",
    "                if isinstance(item['y_targt_chosen_samples'], list): \n",
    "                    to_eval = item['y_targt_chosen_samples'][0]\n",
    "                else:\n",
    "                    to_eval = item['y_targt_chosen_samples']\n",
    "                if to_eval < curr_min:\n",
    "                    single_output.append([to_eval])\n",
    "                else:\n",
    "                    single_output.append([curr_min])\n",
    "            tol_dct = dict(zip(iter(range(1,len(single_output)+1)), single_output))\n",
    "            single_df = pd.DataFrame({'dataset': dataset, 'var': var, \n",
    "                                      'acquisition_method': acquisition_method, \n",
    "                                      'trial':trial,  **tol_dct})\n",
    "            df = pd.concat([df, single_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba38139",
   "metadata": {},
   "outputs": [],
   "source": [
    "othermethods =['gp+ei', 'gp+kg', 'gp+mes', 'gp+ucb']  \n",
    "\n",
    "color_pool = ['C'+str(i) for i in range(2+len(othermethods))]\n",
    "\n",
    "dataset ='CIFAR10-preactrn'  \n",
    "var = 0\n",
    " \n",
    "for j, method in enumerate(othermethods):\n",
    "     \n",
    "    df_inv = df.loc[(df['dataset'] == dataset) & (df['acquisition_method'] == method) & (df['var']==var) ]\n",
    "    out_inv = df_inv.dropna(axis=1).drop(columns=['dataset','acquisition_method','trial','var']).to_numpy()\n",
    "    x = np.arange(1,out_inv.shape[-1]+1)\n",
    "    out_inv = np.abs(out_inv) \n",
    "    y = out_inv.mean(0)\n",
    "    e = out_inv.std(0) # 2*sigma ~ 95% confidence region\n",
    "    plt.plot(x, y, '--', color=color_pool[2+j], label=method) \n",
    "    plt.errorbar(x, y, yerr=[e, e], \n",
    "                 fmt='o', \n",
    "                 color=color_pool[2+j], \n",
    "                 ecolor=color_pool[2+j], \n",
    "                 capsize=3, \n",
    "                 # capthick=0.2, \n",
    "                 alpha=0.4)\n",
    "    plt.scatter(x, y, color=color_pool[2+j], edgecolor='w', zorder=5) # alpha=0.5\n",
    "   \n",
    "\n",
    "\n",
    "df_inv = df.loc[(df['dataset'] == dataset) & (df['acquisition_method'] == 'infmax') & (df['var']==var)]\n",
    "out_inv = df_inv.dropna(axis=1).drop(columns=['dataset','acquisition_method','trial','var']).to_numpy()\n",
    "out_inv = np.abs(out_inv)\n",
    "x = np.arange(1,out_inv.shape[-1]+1)\n",
    "y = out_inv.mean(0)\n",
    "e = out_inv.std(0) # 2*sigma ~ 95% confidence region\n",
    "plt.plot(x, y, '--',  color=color_pool[0], label='infmax')\n",
    "plt.scatter(x, y, color=color_pool[0], edgecolor='w', zorder=5) # edgecolor='w',alpha=0.5\n",
    "\n",
    "plt.errorbar(x, y, yerr=[e, e], \n",
    "             fmt='o', \n",
    "             color=color_pool[0], \n",
    "             ecolor=color_pool[0], \n",
    "             capsize=3,\n",
    "             # capthick=0.2, \n",
    "             alpha=0.4)\n",
    "    \n",
    "\n",
    "xlim_upper = 10\n",
    "xlim_lower = 1\n",
    "\n",
    "ylim_upper = 1.85\n",
    "ylim_lower = 1.60\n",
    "plt.xlabel('Acquisition step')\n",
    "plt.ylabel('Test Regret')\n",
    "plt.xlim([xlim_lower, xlim_upper]) \n",
    "plt.ylim([ylim_lower, ylim_upper]) \n",
    "plt.title(f\"Hyperparameter Optimization\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join('/Users/weichiyao/Desktop/',  f\"HPO_{dataset}_oracle.pdf\") )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearningAL]",
   "language": "python",
   "name": "conda-env-deeplearningAL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
